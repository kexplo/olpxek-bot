import asyncio
import json

import aiohttp
from discord.ext import commands
from rich import print


async def request_llama_stream(prompt: str):
    # LLaMA Prompt:
    # full_prompt = "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n"  # noqa: E501
    # full_prompt += f"### Instructions: \n{prompt}\n\n### Response: \n"
    # 42dot LLM Prompt:
    full_prompt = "í˜¸ê¸°ì‹¬ ë§ì€ ì¸ê°„ (human)ê³¼ ì¸ê³µì§€ëŠ¥ ë´‡ (AI bot)ì˜ ëŒ€í™”ì…ë‹ˆë‹¤. ë´‡ì€ ì¸ê°„ì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê²Œ ìœ ìš©í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. "  # noqa: E501
    full_prompt += f"<human>: {prompt} <bot>:"

    final_response_text = ""
    async with aiohttp.ClientSession() as session:
        async with session.post(
            "http://146.56.128.82:8000/v1/completions",
            json={"prompt": full_prompt, "max_tokens": 1024, "stream": True},
            timeout=60 * 10,
        ) as resp:
            async for data, end_of_http_chunk in resp.content.iter_chunks():
                buffer = data.decode().strip()
                # ignore other responses like ping
                if not buffer.startswith("data: "):
                    continue
                data_string = buffer.removeprefix("data: ")
                if data_string == '[DONE]':
                    return
                try:
                    choice = json.loads(data_string)["choices"][0]
                except json.JSONDecodeError as e:
                    print(f"failed to decode json: {data_string}")
                    raise e
                if choice["finish_reason"] == "stop":
                    return
                final_response_text += choice["text"]
                yield final_response_text


class LLMCog(commands.Cog):
    def __init__(self):
        self.llama_cmd_lock = asyncio.Lock()

    @commands.command(aliases=("ì•ŒíŒŒì¹´", "alpaca", "llama"))
    async def llm(self, ctx, *, arg):
        print(f"LLM request: {arg}")
        async with self.llama_cmd_lock:
            await ctx.message.add_reaction("ğŸ’¬")
            message = await ctx.reply("ğŸ’¬..")
            try:
                async for content in request_llama_stream(arg):
                    if len(content.strip()) > 0:
                        await message.edit(content=content)
            except Exception as e:
                await ctx.message.add_reaction("âŒ")
                print(e)
                prev_content = message.content
                if prev_content:
                    new_content = prev_content + "\n---\n" + str(e)
                else:
                    new_content = str(e)
                await message.edit(content=new_content)
                return
            await ctx.message.add_reaction("âœ…")
            return


if __name__ == "__main__":
    async def test_main():
        async for content in request_llama_stream("ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ”?"):
            print(content)
    asyncio.run(test_main())
